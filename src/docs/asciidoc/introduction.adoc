= Introduction

*Attention: this is introduction is an early draft and may not be accurate, yet*

_serverless_ is a hot topic right now as it simplifies application development tremendously.
It's the next evolutionary step after bundling applications or rather _microservices_ and (embedded) servers into (Docker) containers.

The traditional way to run a web application is to setup a server and deploy the application to the server.
One problem with this approach is that your applications get huge and even if you only need to change a minor thing you need to
re-build and re-deploy the whole application.

An alternative to this approach is to split your application up into multiple modules and deploy each module separately.
Such a module is called a _microservices_.
A _microservice_ typically represents one set of (business) functionality in your application. For example one _microservice_ would deal with user management, another would deal with search functionality and yet another would deal with the ordering process - you get the idea.

Using _microservices_ comes at a price, though. One issue is that your _microservices_ need to communicate with each - typically via REST -
and need to find each other (service discovery). This adds more possible points of failure.
One of the advantages using _microservices_  - if implemented correctly -
is that it's easier to scale your application since it can be done more fine-grained.
You can for example run X instances of your first _microservice_ and Y instances of the second one.

_microservices_ typically get bundled together with an (embedded) HTTP server into a (Docker) container.
To scale the application up, one simply starts a bunch of additional containers.
At the end of the day a container must run on a (Linux) server itself and you pay for a running server.

Now this is finally the point where _serverless_ comes into play. When I refer to _serverless_ I actually mean _Function as a Service_ (_Faas_)
and this means you neither need to run a server to run your containers in, nor do your containers need to run an (embedded) server.
Instead you simply deploy code that gets invoked by an event and responds to it, accordingly, and you only pay when it gets invoked!
While servers and also containers (stateless compute containers) are still involved,
you don't care about it anymore since you don't need to set it up or maintain, anymore.
This is done for you by the _FaaS_ provider! So you can concentrate on writing business logic.

An event for such a _function_ can be an HTTP request, an invocation from another function, a scheduled trigger and so on.

One of the first _FaaS_ providers and the most popular right now is AWS (Amazon Web Services) Lambda but Microsoft has a similar product with Azure Functions and Google also started with Google Cloud Functions, recently.
Since JRestless is a Java framework and AWS Lambda is the only one supporting Java right now, we will focus on that in the following.

JRestless' focus is to provide REST APIs so let's see how a typical _serverless_ architecture looks like.

.basic serverless architecture
[ditaa, "basic_serverless_architecture"]
----
            +----------------+
            | Authentication |
            | Service        |
            +----------------+
                    ^           /----------\
                    |           | Create   |
                    |       +-->| Order    +--+
                    |       |   | Function |  |   +----------+
                    |       |   \----------/  +-->|{s}       |
+----------+   +----+----+  |                     | Order    |
|{o}       |   |         +--+   /----------\  +-->| Database |
| Client   |   | API     |      | Delete   |  |   +----------+
| (browser)+-->| Gateway +----->| Order    +--+
|          |   |         |      | Function |
|          |   |         +--+   \----------/
+----------+   +---------+  |
                            |   /----------\      +----------+
                            |   | User     |      |{s}       |
                            +-->| Function +----->| User     |
                                |          |      | Database |
                                \----------/      +----------+
----

An *_API Gateway_* is a single entry point into an application. It routes requests to _functions_ and actually hides the fact that
an application is spread across multiple _functions_ from clients.
The _API Gateway_ can for example be configured to route all requests to `/user/*` to the "User Function".
In the context of _serverless_ an _API Gateway_ is a managed service. So there's no need to maintain any servers - the cloud provider will take care of this.
In addition to just routing requests to _functions_ it can be used adapt data. Let's say the response body is for different
versions of an API, then we could configure _API Gateway_ to adapt the response from a _function_ differently to the actual response.
The important part here is that the function's response is the same but API Gateway will take care of
creating the correct actual responses for the clients. The same is true for requests.

Another important aspect, here, is the *_Authentication service_*. Instead of letting your _functions_ authenticate users, we can outsource this
to an authentication service (another managed service or _function_ ) and let the _API Gateway_ take care of invoking it an processing the response. For example we could configure _API Gateway_ to limit all requests to `/restricted/\*` to registered users.
This means that the _API Gateway_ will reject requests from unauthenticated users
and _functions_ bound to `/restricted/*` won't get invoked, then. _API Gateway_ will also enhance the request object with information about
the requesting user (user ID and other claims) in order to make it available to the _functions_.

A *_function_* - as shown in the diagram - is nothing else but a _microservice_ (User function) or a _nanoservice_ (Create/Delete Order Function). The important difference is that it's executed upon request, only.
At a minimum a _function_ will receive the (adapted) request body and typically also the request headers, the request method, the (resolved) request URI and other meta data as an object - a POJO in the Java world.
The _function's_ response (POJO) consits of the response body (that might be aggregated by API Gateway, later) at a minimum
and typically also contains the status code and headers.

TODO: mention service discovery

So far so good but why do we need *JRestless*?

. Routing and Transformation
. (Local) Testing
. Portability

In _serverless_ applications you might see a lot of very fine-grained _functions_ like "Create Order Function" and "Delete Order Function".
Such _functions_ are called _nanoservices_ and are considered to be an anti-pattern. The question remains why are they used, then?
In my opinion they are widely used since one needs to take care of routing and transformation manually.
If we use an "Order" _microservice_, instead, the code would look like this:

[source,java]
----
if ("POST".equals(requestMethod) && containsValidOrderId(path)) {
  doCreateOrder(toOrder(body), getOrderId(path));
} else if ("DELETE".equals(requestMethod) && containsValidOrderId(path)) {
  doDeleteOrder(getOrderId(path));
}
...
----
That's a lot of boilerplate code.
So it's tempting to configure the _API Gateway_ to invoke the create/delete function only on POST/DELETE and
if an (valid) order ID is given in the path.

Using JAX-RS, however, we can do routing by simply annotating our endpoints as follows:

[source,java]
----
@Path("/order/{orderId}")
@POST
public Response createOrder(Order order, @PathParam("orderId") int orderId) {
  ...
}
@Path("/order/{orderId}")
@DELETE
public Response deleteOrder(@PathParam("orderId") int orderId) {
  ...
}
----

So JAX-RS - in this example - will make sure that the the correct method gets hit depending on the request method and only if a valid order ID is given in the path.
In addition JAX-RS will automatically transform the path variable orderId from a String into an integer for us and make it available as an argument.
Furthermore the order object in the "create order" case will be created for us - this can be done from JSON or XML, depending on the configuration.

Using JAX-RS also has the huge advantage that you can easily (Unit) test your classes since they are POJOs, as well.
So there's no need to start a container, or create a request object with a JSON/XML body.
Note: for integration testing, you might want to start a container. You can use the Jersey test module to do so.

JRestless, however, is not only about Unit testing. One of the main reasons JRestless was created was to be able to run applications locally.
Doing so requires that you write your application (business logic) using plain JAX-RS. This means that you do NOT depend on any implementation
specifics (servlet, JRestless). So the recommended architecture looks as follows:

.recommended application architecture
[ditaa, "recommended_application_architecture"]
----
+--------------+
|              |
| Function     |
+ (JRestless)  +--+
|              |  |   +---------------+
+--------------+  +-->|               |
                      | plain JAXâ€‘RS  |
                      | Application   |
+--------------+  +-->| (core)        |
|              |  |   +---------------+
| Local        +--+
+ Environment  |
| (e.g. Jetty) |
+--------------+
----

The specific container (JRestless, Jetty, ...) would deal with environment specifics. A typical example for this is authentication.
For each container you would implement an authentication filter that is aware of environment/container specifics but in the end just
sets a Principal. So your application core just receives a principal and does not have to deal with those technical details.

Following this approach gives you another huge advantage: you can easily move your application from JRestless to another container like Jetty.
(Sure, at the end of the day it's not that easy to migrate an application but using JAX-RS in the form of JRestless removes one pain point.)
You might wonder why this matters since _serverless_/_FaaS_ gives you a lot like autoscaling.
Well, when your business grows and your requests increase you probably will get to some point where it's cheaper to run your own infrastructure or you want or need to move to another _FaaS_ provider.

Finally let's get a little technical about JRestless. JRestless is a container for Jersey.
Jersey is the reference implementation for JAX-RS and is widely used.
So when using JRestless you can use most features of the JAX-RS specification (JSON/XML/text/binary/... requests/responses, container request/response filters, ...).
Plus you can use Jersey's extensions! For example its integration for *Spring*.
